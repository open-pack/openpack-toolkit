<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>openpack_toolkit.codalab.operation_segmentation.utils API documentation</title>
<meta name="description" content="Todo:
- Make Unit-Test.
- Refactoring is needed!" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>openpack_toolkit.codalab.operation_segmentation.utils</code></h1>
</header>
<section id="section-intro">
<h2 id="todo">Todo</h2>
<ul>
<li>Make Unit-Test.</li>
<li>Refactoring is needed!</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Todo:
    - Make Unit-Test.
    - Refactoring is needed!
&#34;&#34;&#34;
import json
import os
import zipfile
from logging import getLogger
from pathlib import Path
from typing import Dict, Optional, Tuple

import numpy as np
import pandas as pd
from omegaconf import DictConfig, open_dict

from ...activity import ActSet
from ...configs.datasets.annotations import OPENPACK_OPERATIONS
from .eval import eval_operation_segmentation

logger = getLogger(__name__)

# -----------------------------------------------------------------------------


def resample_prediction_1Hz(
    ts_unix: np.ndarray = None,
    arr: np.ndarray = None,
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Change the sampling rate into 1 Hz.

    Args:
        ts_unix (np.ndarray): 1d array of unixtimestamp. Defaults to None.
        arr (np.ndarray): 1d array of class IDs. Defaults to None.

    Returns:
        Tuple[np.ndarray, np.ndarray]: arrays of unixtime and resampled class ids.
    &#34;&#34;&#34;
    assert arr.ndim == 1
    assert ts_unix.ndim == 1
    assert len(arr) == len(
        ts_unix), f&#34;ts_unix={ts_unix.shape}, arr={arr.shape}&#34;

    tmp = ts_unix - (ts_unix % 1000)
    ts_unix_1hz = np.append(tmp, tmp[-1] + 1000)  # FIXME: write in one line

    delta = (ts_unix_1hz[1:] - ts_unix_1hz[:-1])
    assert delta.min() &gt;= 0, (
        &#34;values in array are expected to be monotonically increasing, &#34;
        f&#34;but the minium step is {delta.min()}.&#34;
    )

    arr_out, ts_unix_out = [], []
    cur_time = ts_unix_1hz[0]
    for r in range(len(ts_unix_1hz)):
        if cur_time != ts_unix_1hz[r]:
            arr_out.append(arr[r - 1])
            ts_unix_out.append(cur_time)
            cur_time = ts_unix_1hz[r]

    return (
        np.array(ts_unix_out),
        np.array(arr_out),
    )


def ffill_missing_elements(
    unixtime_gt: np.ndarray,
    unixtime_pred: np.ndarray,
    prediction: np.ndarray,
):
    missing_timestep = sorted(
        list(set(unixtime_gt.tolist()) - set(unixtime_pred.tolist())))
    if len(missing_timestep) == 0:
        return unixtime_pred, prediction
    logger.warning(
        f&#34;{len(missing_timestep)} elements are missing from prediction.: {missing_timestep}&#34;)

    for ts in missing_timestep:
        ind = np.where(unixtime_gt == ts)[0][0]

        val = prediction[ind - 1] if ind &gt; 0 else -1
        unixtime_pred = np.insert(unixtime_pred, ind, ts)
        prediction = np.insert(prediction, ind, val)

        logger.warning(
            f&#34;fill missing element at ts={ts} (ind={ind}) with {val}.&#34;)

        # DEBUG: Remove before merge
        delta = set(unixtime_gt[:ind]) - set(unixtime_pred[:ind])
        assert len(delta) == 0, delta

    assert len(unixtime_pred) == len(unixtime_gt), (
        f&#34;unixtime_pred={unixtime_pred.shape}, unixtime_gt={unixtime_gt.shape}&#34;
    )
    assert len(prediction) == len(unixtime_gt), (
        f&#34;prediction={prediction.shape}, unixtime_gt={unixtime_gt.shape}&#34;
    )
    return unixtime_pred, prediction


def crop_prediction_sequence(
    unixtime_gt: np.ndarray,
    unixtime_pred: np.ndarray,
    prediction: np.ndarray,
):
    &#34;&#34;&#34;Crop prediction array to have the same timestamp as reference data.
    Args:
        unixtime_gt (np.ndarray): unixtimes of the ground truth sequence
        unixtime_pred (np.ndarray): unixtimes of the prediction sequence
        prediction (np.ndarray): -
    &#34;&#34;&#34;
    ts_head, ts_tail = unixtime_gt[0], unixtime_gt[-1]
    logger.debug(f&#34;ground truth: ts_head={ts_head}, ts_tail={ts_tail}&#34;)
    logger.debug(
        f&#34;prediction  : ts_head={int(unixtime_pred[0])}, ts_tail={int(unixtime_pred[-1])}&#34;)

    ind = np.where((unixtime_pred &gt;= ts_head) &amp; (unixtime_pred &lt;= ts_tail))[0]
    logger.debug(
        f&#34;ind={ind.shape}, unixtime_pred={unixtime_pred.shape}, prediction={prediction.shape}&#34;)

    unixtime_pred = unixtime_pred[ind]
    prediction = prediction[ind]

    unixtime_pred, prediction = ffill_missing_elements(
        unixtime_gt,
        unixtime_pred,
        prediction,
    )

    return unixtime_pred, prediction


def construct_submission_dict(
    outputs: Dict[str, Dict[str, np.ndarray]],
    act_set: ActSet,
    include_ground_truth: Optional[bool] = False,
    cfg: Optional[DictConfig] = None,
) -&gt; Dict:
    &#34;&#34;&#34;Make dict that can be used for submission and `eval_workprocess_segmentation()` func.
    Args:
        outputs (Dict[str, Dict[str, np.ndarray]]): key is expected to be a pair of user and
            session. e.g., &#34;U0102-S0100&#34;.
        act_set (ActSet): -
        include_ground_truth (bool, optional): If True, ground truth labels are included
            in the submission dict. Set True when you calculate scores.
        cfg (DictConfig, optional): config dict.
    Returns:
        Dict: submission dict
    &#34;&#34;&#34;
    submission = dict()

    keys = sorted(outputs.keys())
    for key in keys:
        d = outputs[key]
        record = dict()
        user, session = key.split(&#34;-&#34;)

        assert d[&#34;y&#34;].ndim == 3
        assert d[&#34;unixtime&#34;].dtype == np.int64, (
            &#34;unixtime must be np.int64, but got {}&#34;.format(d[&#34;unixtime&#34;].dtype)
        )

        prediction_sess = act_set.convert_index_to_id(
            np.argmax(d[&#34;y&#34;], axis=1).ravel())
        unixtime_pred_sess, prediction_sess = resample_prediction_1Hz(
            ts_unix=d[&#34;unixtime&#34;].copy().ravel(), arr=prediction_sess)

        if include_ground_truth:
            with open_dict(cfg):
                cfg.user = {&#34;name&#34;: user}
                cfg.session = session

            # TODO: Move to new function ( load_ground_truth() )
            if hasattr(cfg.dataset.annotation, &#34;spec&#34;):
                path = Path(
                    cfg.dataset.annotation.spec.path.dir,
                    cfg.dataset.annotation.spec.path.fname
                )
            else:
                path = Path(
                    cfg.dataset.annotation.path.dir,
                    cfg.dataset.annotation.path.fname
                )
            df_label = pd.read_csv(path)

            label_format = cfg.dataset.annotation.metadata.labels.get(
                &#34;label_format&#34;, &#34;&#34;)
            if label_format == &#34;soft-target&#34;:
                cols = [c for c in df_label.columns if c.startswith(&#34;ID&#34;)]
                index_to_id = {i: int(c.replace(&#34;ID&#34;, &#34;&#34;))
                               for i, c in enumerate(cols)}
                df_label[&#34;index&#34;] = np.argmax(df_label[cols].values, axis=1)
                df_label[&#34;id&#34;] = df_label[&#34;index&#34;].apply(
                    lambda ind: index_to_id[ind])

            unixtime_gt_sess = df_label[&#34;unixtime&#34;].values
            ground_truth_sess = df_label[&#34;id&#34;].values

            # check timestamp
            unixtime_pred_sess, prediction_sess = crop_prediction_sequence(
                unixtime_gt_sess, unixtime_pred_sess, prediction_sess)
            np.testing.assert_array_equal(unixtime_pred_sess, unixtime_gt_sess)

            record[&#34;ground_truth&#34;] = ground_truth_sess.copy()

        record[&#34;unixtime&#34;] = unixtime_pred_sess.copy()
        record[&#34;prediction&#34;] = prediction_sess.copy()
        submission[key] = record

    return submission


def make_submission_zipfile(
        submission: Dict,
        logdir: Path,
        metadata: dict = None) -&gt; None:
    &#34;&#34;&#34;Check dict contents and generate zip file for codalab submission.

    Args:
        submission (Dict): submission dict
        logdir (Path): path to the output directory
        metadata (dict): dict of additional information that is included in
            ``submission.json``. We recommend to include a data split name.
    Returns:
        None (make JSON &amp; zip files)
    &#34;&#34;&#34;
    # Check data format and convert into pure objects
    submission_clean = dict()
    for key, d in submission.items():
        assert isinstance(d, dict)

        record = dict()
        for arr_name, arr in d.items():
            if arr_name not in (&#34;prediction&#34;, &#34;unixtime&#34;):
                logger.warning(
                    f&#34;unexpected entry[{arr_name}] is found in submission dict.&#34;)
            assert isinstance(arr, np.ndarray)
            record[arr_name] = arr.tolist()
        submission_clean[key] = record

    # Add meta data
    if metadata is not None:
        submission_clean[&#34;meta&#34;] = metadata

    # Write JSON file
    path_json = Path(logdir, &#34;submission.json&#34;)
    if path_json.exists():
        os.remove(path_json)
    with open(path_json, &#34;w&#34;) as f:
        json.dump(submission_clean, f)
    logger.info(f&#34;write submission.json to {path_json}&#34;)

    # Make zip file
    path_zip = Path(logdir, &#34;submission.zip&#34;)
    if path_zip.exists():
        os.remove(path_zip)
    with zipfile.ZipFile(path_zip, &#34;w&#34;) as zf:
        zf.write(path_json, arcname=&#34;./submission.json&#34;)
    logger.info(f&#34;write submission.zip to {path_zip}&#34;)


# -----------------------------------------------------------------------------

def eval_operation_segmentation_wrapper(
    cfg: DictConfig,
    outputs: Dict[str, Dict[str, np.ndarray]],
    act_set: ActSet = ActSet(OPENPACK_OPERATIONS),
    exclude_ignore_class=True,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Compute evaluation metrics from model outputs (predicted probability).
    Args:
        cfg (DictConfig): config dict.
        outputs (Dict[str, Dict[str, np.ndarray]]): dict object that contains t_idx and y.
            t_idx is a 2d array of target class index with shape=(BATCH_SIZE, WINDOW).
            y is a 3d array of predction probabilities with shape=(BATCH_SIZE, NUM_CLASSES, WINDOW).
        act_set (ActSete, optional): class definition.
        exclude_ignore_class (bool): If true, ignore classes are excluded. (default: True)
    Returns:
        pd.DataFrame
    &#34;&#34;&#34;
    submission = construct_submission_dict(
        outputs, act_set, include_ground_truth=True, cfg=cfg)
    classes = act_set.to_tuple()
    ignore_class_id = act_set.get_ignore_class_id()
    if isinstance(ignore_class_id, tuple):
        raise NotImplementedError()

    # Evaluate
    df_scores = []
    t_id_concat, y_id_concat = [], []
    for key, d in submission.items():
        t_id = d[&#34;ground_truth&#34;]
        y_id = d[&#34;prediction&#34;]

        t_id_concat.append(t_id.copy())
        y_id_concat.append(y_id.copy())

        df_tmp = eval_operation_segmentation(
            t_id,
            y_id,
            classes=classes,
            ignore_class_id=ignore_class_id,
            mode=None)
        df_tmp[&#34;key&#34;] = key
        df_scores.append(df_tmp.reset_index(drop=False))

    # Overall Score
    df_tmp = eval_operation_segmentation(
        np.concatenate(t_id_concat, axis=0),
        np.concatenate(y_id_concat, axis=0),
        classes=classes,
        ignore_class_id=ignore_class_id,
        mode=None,
    )
    df_tmp[&#34;key&#34;] = &#34;all&#34;
    df_scores.append(df_tmp.reset_index(drop=False))

    df_scores = pd.concat(df_scores, axis=0, ignore_index=True)
    return df_scores</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="openpack_toolkit.codalab.operation_segmentation.utils.construct_submission_dict"><code class="name flex">
<span>def <span class="ident">construct_submission_dict</span></span>(<span>outputs: Dict[str, Dict[str, numpy.ndarray]], act_set: <a title="openpack_toolkit.activity.ActSet" href="../../activity/index.html#openpack_toolkit.activity.ActSet">ActSet</a>, include_ground_truth: Optional[bool] = False, cfg: Optional[omegaconf.dictconfig.DictConfig] = None) ‑> Dict</span>
</code></dt>
<dd>
<div class="desc"><p>Make dict that can be used for submission and <code>eval_workprocess_segmentation()</code> func.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outputs</code></strong> :&ensp;<code>Dict[str, Dict[str, np.ndarray]]</code></dt>
<dd>key is expected to be a pair of user and
session. e.g., "U0102-S0100".</dd>
<dt><strong><code>act_set</code></strong> :&ensp;<code>ActSet</code></dt>
<dd>-</dd>
<dt><strong><code>include_ground_truth</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, ground truth labels are included
in the submission dict. Set True when you calculate scores.</dd>
<dt><strong><code>cfg</code></strong> :&ensp;<code>DictConfig</code>, optional</dt>
<dd>config dict.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict</code></dt>
<dd>submission dict</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_submission_dict(
    outputs: Dict[str, Dict[str, np.ndarray]],
    act_set: ActSet,
    include_ground_truth: Optional[bool] = False,
    cfg: Optional[DictConfig] = None,
) -&gt; Dict:
    &#34;&#34;&#34;Make dict that can be used for submission and `eval_workprocess_segmentation()` func.
    Args:
        outputs (Dict[str, Dict[str, np.ndarray]]): key is expected to be a pair of user and
            session. e.g., &#34;U0102-S0100&#34;.
        act_set (ActSet): -
        include_ground_truth (bool, optional): If True, ground truth labels are included
            in the submission dict. Set True when you calculate scores.
        cfg (DictConfig, optional): config dict.
    Returns:
        Dict: submission dict
    &#34;&#34;&#34;
    submission = dict()

    keys = sorted(outputs.keys())
    for key in keys:
        d = outputs[key]
        record = dict()
        user, session = key.split(&#34;-&#34;)

        assert d[&#34;y&#34;].ndim == 3
        assert d[&#34;unixtime&#34;].dtype == np.int64, (
            &#34;unixtime must be np.int64, but got {}&#34;.format(d[&#34;unixtime&#34;].dtype)
        )

        prediction_sess = act_set.convert_index_to_id(
            np.argmax(d[&#34;y&#34;], axis=1).ravel())
        unixtime_pred_sess, prediction_sess = resample_prediction_1Hz(
            ts_unix=d[&#34;unixtime&#34;].copy().ravel(), arr=prediction_sess)

        if include_ground_truth:
            with open_dict(cfg):
                cfg.user = {&#34;name&#34;: user}
                cfg.session = session

            # TODO: Move to new function ( load_ground_truth() )
            if hasattr(cfg.dataset.annotation, &#34;spec&#34;):
                path = Path(
                    cfg.dataset.annotation.spec.path.dir,
                    cfg.dataset.annotation.spec.path.fname
                )
            else:
                path = Path(
                    cfg.dataset.annotation.path.dir,
                    cfg.dataset.annotation.path.fname
                )
            df_label = pd.read_csv(path)

            label_format = cfg.dataset.annotation.metadata.labels.get(
                &#34;label_format&#34;, &#34;&#34;)
            if label_format == &#34;soft-target&#34;:
                cols = [c for c in df_label.columns if c.startswith(&#34;ID&#34;)]
                index_to_id = {i: int(c.replace(&#34;ID&#34;, &#34;&#34;))
                               for i, c in enumerate(cols)}
                df_label[&#34;index&#34;] = np.argmax(df_label[cols].values, axis=1)
                df_label[&#34;id&#34;] = df_label[&#34;index&#34;].apply(
                    lambda ind: index_to_id[ind])

            unixtime_gt_sess = df_label[&#34;unixtime&#34;].values
            ground_truth_sess = df_label[&#34;id&#34;].values

            # check timestamp
            unixtime_pred_sess, prediction_sess = crop_prediction_sequence(
                unixtime_gt_sess, unixtime_pred_sess, prediction_sess)
            np.testing.assert_array_equal(unixtime_pred_sess, unixtime_gt_sess)

            record[&#34;ground_truth&#34;] = ground_truth_sess.copy()

        record[&#34;unixtime&#34;] = unixtime_pred_sess.copy()
        record[&#34;prediction&#34;] = prediction_sess.copy()
        submission[key] = record

    return submission</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.utils.crop_prediction_sequence"><code class="name flex">
<span>def <span class="ident">crop_prediction_sequence</span></span>(<span>unixtime_gt: numpy.ndarray, unixtime_pred: numpy.ndarray, prediction: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop prediction array to have the same timestamp as reference data.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>unixtime_gt</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>unixtimes of the ground truth sequence</dd>
<dt><strong><code>unixtime_pred</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>unixtimes of the prediction sequence</dd>
<dt><strong><code>prediction</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>-</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_prediction_sequence(
    unixtime_gt: np.ndarray,
    unixtime_pred: np.ndarray,
    prediction: np.ndarray,
):
    &#34;&#34;&#34;Crop prediction array to have the same timestamp as reference data.
    Args:
        unixtime_gt (np.ndarray): unixtimes of the ground truth sequence
        unixtime_pred (np.ndarray): unixtimes of the prediction sequence
        prediction (np.ndarray): -
    &#34;&#34;&#34;
    ts_head, ts_tail = unixtime_gt[0], unixtime_gt[-1]
    logger.debug(f&#34;ground truth: ts_head={ts_head}, ts_tail={ts_tail}&#34;)
    logger.debug(
        f&#34;prediction  : ts_head={int(unixtime_pred[0])}, ts_tail={int(unixtime_pred[-1])}&#34;)

    ind = np.where((unixtime_pred &gt;= ts_head) &amp; (unixtime_pred &lt;= ts_tail))[0]
    logger.debug(
        f&#34;ind={ind.shape}, unixtime_pred={unixtime_pred.shape}, prediction={prediction.shape}&#34;)

    unixtime_pred = unixtime_pred[ind]
    prediction = prediction[ind]

    unixtime_pred, prediction = ffill_missing_elements(
        unixtime_gt,
        unixtime_pred,
        prediction,
    )

    return unixtime_pred, prediction</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.utils.eval_operation_segmentation_wrapper"><code class="name flex">
<span>def <span class="ident">eval_operation_segmentation_wrapper</span></span>(<span>cfg: omegaconf.dictconfig.DictConfig, outputs: Dict[str, Dict[str, numpy.ndarray]], act_set: <a title="openpack_toolkit.activity.ActSet" href="../../activity/index.html#openpack_toolkit.activity.ActSet">ActSet</a> = ActSet(classes=(Label(id=100, name='Picking', version='v3.0.0', is_ignore=False, category=None, event=None), Label(id=200, name='Relocate Item Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=300, name='Assemble Box', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=400, name='Insert Items', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=500, name='Close Box', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=600, name='Attach Box Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=700, name='Scan Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=800, name='Attach Shipping Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=900, name='Put on Back Table', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=1000, name='Fill out Order', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=8100, name='Null', version='v3.2.2', is_ignore=True, category=None, event=None))), exclude_ignore_class=True) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Compute evaluation metrics from model outputs (predicted probability).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong> :&ensp;<code>DictConfig</code></dt>
<dd>config dict.</dd>
<dt><strong><code>outputs</code></strong> :&ensp;<code>Dict[str, Dict[str, np.ndarray]]</code></dt>
<dd>dict object that contains t_idx and y.
t_idx is a 2d array of target class index with shape=(BATCH_SIZE, WINDOW).
y is a 3d array of predction probabilities with shape=(BATCH_SIZE, NUM_CLASSES, WINDOW).</dd>
<dt><strong><code>act_set</code></strong> :&ensp;<code>ActSete</code>, optional</dt>
<dd>class definition.</dd>
<dt><strong><code>exclude_ignore_class</code></strong> :&ensp;<code>bool</code></dt>
<dd>If true, ignore classes are excluded. (default: True)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_operation_segmentation_wrapper(
    cfg: DictConfig,
    outputs: Dict[str, Dict[str, np.ndarray]],
    act_set: ActSet = ActSet(OPENPACK_OPERATIONS),
    exclude_ignore_class=True,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Compute evaluation metrics from model outputs (predicted probability).
    Args:
        cfg (DictConfig): config dict.
        outputs (Dict[str, Dict[str, np.ndarray]]): dict object that contains t_idx and y.
            t_idx is a 2d array of target class index with shape=(BATCH_SIZE, WINDOW).
            y is a 3d array of predction probabilities with shape=(BATCH_SIZE, NUM_CLASSES, WINDOW).
        act_set (ActSete, optional): class definition.
        exclude_ignore_class (bool): If true, ignore classes are excluded. (default: True)
    Returns:
        pd.DataFrame
    &#34;&#34;&#34;
    submission = construct_submission_dict(
        outputs, act_set, include_ground_truth=True, cfg=cfg)
    classes = act_set.to_tuple()
    ignore_class_id = act_set.get_ignore_class_id()
    if isinstance(ignore_class_id, tuple):
        raise NotImplementedError()

    # Evaluate
    df_scores = []
    t_id_concat, y_id_concat = [], []
    for key, d in submission.items():
        t_id = d[&#34;ground_truth&#34;]
        y_id = d[&#34;prediction&#34;]

        t_id_concat.append(t_id.copy())
        y_id_concat.append(y_id.copy())

        df_tmp = eval_operation_segmentation(
            t_id,
            y_id,
            classes=classes,
            ignore_class_id=ignore_class_id,
            mode=None)
        df_tmp[&#34;key&#34;] = key
        df_scores.append(df_tmp.reset_index(drop=False))

    # Overall Score
    df_tmp = eval_operation_segmentation(
        np.concatenate(t_id_concat, axis=0),
        np.concatenate(y_id_concat, axis=0),
        classes=classes,
        ignore_class_id=ignore_class_id,
        mode=None,
    )
    df_tmp[&#34;key&#34;] = &#34;all&#34;
    df_scores.append(df_tmp.reset_index(drop=False))

    df_scores = pd.concat(df_scores, axis=0, ignore_index=True)
    return df_scores</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.utils.ffill_missing_elements"><code class="name flex">
<span>def <span class="ident">ffill_missing_elements</span></span>(<span>unixtime_gt: numpy.ndarray, unixtime_pred: numpy.ndarray, prediction: numpy.ndarray)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ffill_missing_elements(
    unixtime_gt: np.ndarray,
    unixtime_pred: np.ndarray,
    prediction: np.ndarray,
):
    missing_timestep = sorted(
        list(set(unixtime_gt.tolist()) - set(unixtime_pred.tolist())))
    if len(missing_timestep) == 0:
        return unixtime_pred, prediction
    logger.warning(
        f&#34;{len(missing_timestep)} elements are missing from prediction.: {missing_timestep}&#34;)

    for ts in missing_timestep:
        ind = np.where(unixtime_gt == ts)[0][0]

        val = prediction[ind - 1] if ind &gt; 0 else -1
        unixtime_pred = np.insert(unixtime_pred, ind, ts)
        prediction = np.insert(prediction, ind, val)

        logger.warning(
            f&#34;fill missing element at ts={ts} (ind={ind}) with {val}.&#34;)

        # DEBUG: Remove before merge
        delta = set(unixtime_gt[:ind]) - set(unixtime_pred[:ind])
        assert len(delta) == 0, delta

    assert len(unixtime_pred) == len(unixtime_gt), (
        f&#34;unixtime_pred={unixtime_pred.shape}, unixtime_gt={unixtime_gt.shape}&#34;
    )
    assert len(prediction) == len(unixtime_gt), (
        f&#34;prediction={prediction.shape}, unixtime_gt={unixtime_gt.shape}&#34;
    )
    return unixtime_pred, prediction</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.utils.make_submission_zipfile"><code class="name flex">
<span>def <span class="ident">make_submission_zipfile</span></span>(<span>submission: Dict, logdir: pathlib.Path, metadata: dict = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Check dict contents and generate zip file for codalab submission.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>submission</code></strong> :&ensp;<code>Dict</code></dt>
<dd>submission dict</dd>
<dt><strong><code>logdir</code></strong> :&ensp;<code>Path</code></dt>
<dd>path to the output directory</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>dict of additional information that is included in
<code>submission.json</code>. We recommend to include a data split name.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None (make JSON &amp; zip files)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_submission_zipfile(
        submission: Dict,
        logdir: Path,
        metadata: dict = None) -&gt; None:
    &#34;&#34;&#34;Check dict contents and generate zip file for codalab submission.

    Args:
        submission (Dict): submission dict
        logdir (Path): path to the output directory
        metadata (dict): dict of additional information that is included in
            ``submission.json``. We recommend to include a data split name.
    Returns:
        None (make JSON &amp; zip files)
    &#34;&#34;&#34;
    # Check data format and convert into pure objects
    submission_clean = dict()
    for key, d in submission.items():
        assert isinstance(d, dict)

        record = dict()
        for arr_name, arr in d.items():
            if arr_name not in (&#34;prediction&#34;, &#34;unixtime&#34;):
                logger.warning(
                    f&#34;unexpected entry[{arr_name}] is found in submission dict.&#34;)
            assert isinstance(arr, np.ndarray)
            record[arr_name] = arr.tolist()
        submission_clean[key] = record

    # Add meta data
    if metadata is not None:
        submission_clean[&#34;meta&#34;] = metadata

    # Write JSON file
    path_json = Path(logdir, &#34;submission.json&#34;)
    if path_json.exists():
        os.remove(path_json)
    with open(path_json, &#34;w&#34;) as f:
        json.dump(submission_clean, f)
    logger.info(f&#34;write submission.json to {path_json}&#34;)

    # Make zip file
    path_zip = Path(logdir, &#34;submission.zip&#34;)
    if path_zip.exists():
        os.remove(path_zip)
    with zipfile.ZipFile(path_zip, &#34;w&#34;) as zf:
        zf.write(path_json, arcname=&#34;./submission.json&#34;)
    logger.info(f&#34;write submission.zip to {path_zip}&#34;)</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.utils.resample_prediction_1Hz"><code class="name flex">
<span>def <span class="ident">resample_prediction_1Hz</span></span>(<span>ts_unix: numpy.ndarray = None, arr: numpy.ndarray = None) ‑> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Change the sampling rate into 1 Hz.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ts_unix</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>1d array of unixtimestamp. Defaults to None.</dd>
<dt><strong><code>arr</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>1d array of class IDs. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, np.ndarray]</code></dt>
<dd>arrays of unixtime and resampled class ids.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resample_prediction_1Hz(
    ts_unix: np.ndarray = None,
    arr: np.ndarray = None,
) -&gt; Tuple[np.ndarray, np.ndarray]:
    &#34;&#34;&#34;Change the sampling rate into 1 Hz.

    Args:
        ts_unix (np.ndarray): 1d array of unixtimestamp. Defaults to None.
        arr (np.ndarray): 1d array of class IDs. Defaults to None.

    Returns:
        Tuple[np.ndarray, np.ndarray]: arrays of unixtime and resampled class ids.
    &#34;&#34;&#34;
    assert arr.ndim == 1
    assert ts_unix.ndim == 1
    assert len(arr) == len(
        ts_unix), f&#34;ts_unix={ts_unix.shape}, arr={arr.shape}&#34;

    tmp = ts_unix - (ts_unix % 1000)
    ts_unix_1hz = np.append(tmp, tmp[-1] + 1000)  # FIXME: write in one line

    delta = (ts_unix_1hz[1:] - ts_unix_1hz[:-1])
    assert delta.min() &gt;= 0, (
        &#34;values in array are expected to be monotonically increasing, &#34;
        f&#34;but the minium step is {delta.min()}.&#34;
    )

    arr_out, ts_unix_out = [], []
    cur_time = ts_unix_1hz[0]
    for r in range(len(ts_unix_1hz)):
        if cur_time != ts_unix_1hz[r]:
            arr_out.append(arr[r - 1])
            ts_unix_out.append(cur_time)
            cur_time = ts_unix_1hz[r]

    return (
        np.array(ts_unix_out),
        np.array(arr_out),
    )</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation" href="index.html">openpack_toolkit.codalab.operation_segmentation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils.construct_submission_dict" href="#openpack_toolkit.codalab.operation_segmentation.utils.construct_submission_dict">construct_submission_dict</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils.crop_prediction_sequence" href="#openpack_toolkit.codalab.operation_segmentation.utils.crop_prediction_sequence">crop_prediction_sequence</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils.eval_operation_segmentation_wrapper" href="#openpack_toolkit.codalab.operation_segmentation.utils.eval_operation_segmentation_wrapper">eval_operation_segmentation_wrapper</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils.ffill_missing_elements" href="#openpack_toolkit.codalab.operation_segmentation.utils.ffill_missing_elements">ffill_missing_elements</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils.make_submission_zipfile" href="#openpack_toolkit.codalab.operation_segmentation.utils.make_submission_zipfile">make_submission_zipfile</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils.resample_prediction_1Hz" href="#openpack_toolkit.codalab.operation_segmentation.utils.resample_prediction_1Hz">resample_prediction_1Hz</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>