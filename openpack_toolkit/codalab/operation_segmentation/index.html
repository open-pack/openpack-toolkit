<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>openpack_toolkit.codalab.operation_segmentation API documentation</title>
<meta name="description" content="Evaluation codes for Operation Semantic Segmentation Task …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>openpack_toolkit.codalab.operation_segmentation</code></h1>
</header>
<section id="section-intro">
<p>Evaluation codes for Operation Semantic Segmentation Task</p>
<p>This task is aimed to recognize 9 operations in the manual packing activity.
F1-measure with macro average is used as metrics.</p>
<h2 id="note">Note</h2>
<p>OpenPack Challenge uses <code><a title="openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation" href="#openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation">eval_operation_segmentation()</a></code> in <code>eval.py</code> for evaluation.</p>
<h2 id="todo">Todo</h2>
<ul>
<li>Add task desciption.</li>
<li>Add usage (data format)</li>
<li>Add detail desciption of evaluation format.</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Evaluation codes for Operation Semantic Segmentation Task

This task is aimed to recognize 9 operations in the manual packing activity.
F1-measure with macro average is used as metrics.

Note:
    OpenPack Challenge uses `eval_operation_segmentation()` in `eval.py` for evaluation.

Todo:
    * Add task desciption.
    * Add usage (data format)
    * Add detail desciption of evaluation format.
&#34;&#34;&#34;
from .eval import eval_operation_segmentation
from .utils import (
    construct_submission_dict,
    eval_operation_segmentation_wrapper,
    make_submission_zipfile,
)

__all__ = [
    &#34;construct_submission_dict&#34;,
    &#34;eval_operation_segmentation&#34;,
    &#34;eval_operation_segmentation_wrapper&#34;,
    &#34;make_submission_zipfile&#34;,
]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="openpack_toolkit.codalab.operation_segmentation.eval" href="eval.html">openpack_toolkit.codalab.operation_segmentation.eval</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="openpack_toolkit.codalab.operation_segmentation.utils" href="utils.html">openpack_toolkit.codalab.operation_segmentation.utils</a></code></dt>
<dd>
<div class="desc"><h2 id="todo">Todo</h2>
<ul>
<li>Make Unit-Test.</li>
<li>Refactoring is needed!</li>
</ul></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="openpack_toolkit.codalab.operation_segmentation.construct_submission_dict"><code class="name flex">
<span>def <span class="ident">construct_submission_dict</span></span>(<span>outputs: Dict[str, Dict[str, numpy.ndarray]], act_set: <a title="openpack_toolkit.activity.ActSet" href="../../activity/index.html#openpack_toolkit.activity.ActSet">ActSet</a>, include_ground_truth: Optional[bool] = False, cfg: Optional[omegaconf.dictconfig.DictConfig] = None) ‑> Dict</span>
</code></dt>
<dd>
<div class="desc"><p>Make dict that can be used for submission and <code>eval_workprocess_segmentation()</code> func.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outputs</code></strong> :&ensp;<code>Dict[str, Dict[str, np.ndarray]]</code></dt>
<dd>key is expected to be a pair of user and
session. e.g., "U0102-S0100".</dd>
<dt><strong><code>act_set</code></strong> :&ensp;<code>ActSet</code></dt>
<dd>-</dd>
<dt><strong><code>include_ground_truth</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, ground truth labels are included
in the submission dict. Set True when you calculate scores.</dd>
<dt><strong><code>cfg</code></strong> :&ensp;<code>DictConfig</code>, optional</dt>
<dd>config dict.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict</code></dt>
<dd>submission dict</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def construct_submission_dict(
    outputs: Dict[str, Dict[str, np.ndarray]],
    act_set: ActSet,
    include_ground_truth: Optional[bool] = False,
    cfg: Optional[DictConfig] = None,
) -&gt; Dict:
    &#34;&#34;&#34;Make dict that can be used for submission and `eval_workprocess_segmentation()` func.
    Args:
        outputs (Dict[str, Dict[str, np.ndarray]]): key is expected to be a pair of user and
            session. e.g., &#34;U0102-S0100&#34;.
        act_set (ActSet): -
        include_ground_truth (bool, optional): If True, ground truth labels are included
            in the submission dict. Set True when you calculate scores.
        cfg (DictConfig, optional): config dict.
    Returns:
        Dict: submission dict
    &#34;&#34;&#34;
    submission = dict()

    keys = sorted(outputs.keys())
    for key in keys:
        d = outputs[key]
        record = dict()
        user, session = key.split(&#34;-&#34;)

        assert d[&#34;y&#34;].ndim == 3
        assert d[&#34;unixtime&#34;].dtype == np.int64, (
            &#34;unixtime must be np.int64, but got {}&#34;.format(d[&#34;unixtime&#34;].dtype)
        )

        prediction_sess = act_set.convert_index_to_id(
            np.argmax(d[&#34;y&#34;], axis=1).ravel())
        unixtime_pred_sess, prediction_sess = resample_prediction_1Hz(
            ts_unix=d[&#34;unixtime&#34;].copy().ravel(), arr=prediction_sess)

        if include_ground_truth:
            with open_dict(cfg):
                cfg.user = {&#34;name&#34;: user}
                cfg.session = session

            # TODO: Move to new function ( load_ground_truth() )
            if hasattr(cfg.dataset.annotation, &#34;spec&#34;):
                path = Path(
                    cfg.dataset.annotation.spec.path.dir,
                    cfg.dataset.annotation.spec.path.fname
                )
            else:
                path = Path(
                    cfg.dataset.annotation.path.dir,
                    cfg.dataset.annotation.path.fname
                )
            df_label = pd.read_csv(path)

            label_format = cfg.dataset.annotation.metadata.labels.get(
                &#34;label_format&#34;, &#34;&#34;)
            if label_format == &#34;soft-target&#34;:
                cols = [c for c in df_label.columns if c.startswith(&#34;ID&#34;)]
                index_to_id = {i: int(c.replace(&#34;ID&#34;, &#34;&#34;))
                               for i, c in enumerate(cols)}
                df_label[&#34;index&#34;] = np.argmax(df_label[cols].values, axis=1)
                df_label[&#34;id&#34;] = df_label[&#34;index&#34;].apply(
                    lambda ind: index_to_id[ind])

            unixtime_gt_sess = df_label[&#34;unixtime&#34;].values
            ground_truth_sess = df_label[&#34;id&#34;].values

            # check timestamp
            unixtime_pred_sess, prediction_sess = crop_prediction_sequence(
                unixtime_gt_sess, unixtime_pred_sess, prediction_sess)
            np.testing.assert_array_equal(unixtime_pred_sess, unixtime_gt_sess)

            record[&#34;ground_truth&#34;] = ground_truth_sess.copy()

        record[&#34;unixtime&#34;] = unixtime_pred_sess.copy()
        record[&#34;prediction&#34;] = prediction_sess.copy()
        submission[key] = record

    return submission</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation"><code class="name flex">
<span>def <span class="ident">eval_operation_segmentation</span></span>(<span>t_id: numpy.ndarray = None, y_id: numpy.ndarray = None, classes: Tuple[Tuple[int, str], ...] = None, ignore_class_id: int = None, mode: str = 'final') ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Compute metrics (i.e., precision, recall, f1, support) for the given sequence.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>t_id</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>unixtime and corresponding activity ID, shape=(T,)</dd>
<dt><strong><code>y_id</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>unixtime and predicted activity ID, shape=(T,)</dd>
<dt><strong><code>classes</code></strong> :&ensp;<code>Tuple</code></dt>
<dd>class definition. pairs of class id and name.</dd>
<dt><strong><code>mode</code></strong> :&ensp;<code>str</code></dt>
<dd>If final, only the macro score will be calculated. Otherwise,
macro avg., weighted avg., and score for each class will be calculated.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_operation_segmentation(
    t_id: np.ndarray = None,
    y_id: np.ndarray = None,
    classes: Tuple[Tuple[int, str], ...] = None,
    ignore_class_id: int = None,
    mode: str = &#34;final&#34;,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Compute metrics (i.e., precision, recall, f1, support) for the given sequence.
    Args:
        t_id (np.ndarray): unixtime and corresponding activity ID, shape=(T,)
        y_id (np.ndarray): unixtime and predicted activity ID, shape=(T,)
        classes (Tuple): class definition. pairs of class id and name.
        mode (str): If final, only the macro score will be calculated. Otherwise,
            macro avg., weighted avg., and score for each class will be calculated.
    Returns:
        pd.DataFrame
    &#34;&#34;&#34;
    assert t_id.ndim == 1
    assert y_id.ndim == 1
    verify_class_ids(y_id, classes)

    if ignore_class_id is not None:
        t_id, y_id = drop_ignore_class(t_id, y_id, ignore_class_id)
        classes = tuple([t for t in classes if t[0] != ignore_class_id])

    df_scores = [
        calc_avg_metrics(t_id, y_id, classes, average=&#34;macro&#34;),
        calc_avg_metrics(t_id, y_id, classes, average=&#34;weighted&#34;),
    ]
    if mode != &#34;final&#34;:
        df_scores.append(
            calc_class_metrics(t_id, y_id, classes)
        )

    df_scores = pd.concat(
        df_scores,
        axis=0,
        ignore_index=True).set_index(&#34;name&#34;)
    return df_scores</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation_wrapper"><code class="name flex">
<span>def <span class="ident">eval_operation_segmentation_wrapper</span></span>(<span>cfg: omegaconf.dictconfig.DictConfig, outputs: Dict[str, Dict[str, numpy.ndarray]], act_set: <a title="openpack_toolkit.activity.ActSet" href="../../activity/index.html#openpack_toolkit.activity.ActSet">ActSet</a> = ActSet(classes=(Label(id=100, name='Picking', version='v3.0.0', is_ignore=False, category=None, event=None), Label(id=200, name='Relocate Item Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=300, name='Assemble Box', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=400, name='Insert Items', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=500, name='Close Box', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=600, name='Attach Box Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=700, name='Scan Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=800, name='Attach Shipping Label', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=900, name='Put on Back Table', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=1000, name='Fill out Order', version='v3.2.2', is_ignore=False, category=None, event=None), Label(id=8100, name='Null', version='v3.2.2', is_ignore=True, category=None, event=None))), exclude_ignore_class=True) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Compute evaluation metrics from model outputs (predicted probability).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cfg</code></strong> :&ensp;<code>DictConfig</code></dt>
<dd>config dict.</dd>
<dt><strong><code>outputs</code></strong> :&ensp;<code>Dict[str, Dict[str, np.ndarray]]</code></dt>
<dd>dict object that contains t_idx and y.
t_idx is a 2d array of target class index with shape=(BATCH_SIZE, WINDOW).
y is a 3d array of predction probabilities with shape=(BATCH_SIZE, NUM_CLASSES, WINDOW).</dd>
<dt><strong><code>act_set</code></strong> :&ensp;<code>ActSete</code>, optional</dt>
<dd>class definition.</dd>
<dt><strong><code>exclude_ignore_class</code></strong> :&ensp;<code>bool</code></dt>
<dd>If true, ignore classes are excluded. (default: True)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>pd.DataFrame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eval_operation_segmentation_wrapper(
    cfg: DictConfig,
    outputs: Dict[str, Dict[str, np.ndarray]],
    act_set: ActSet = ActSet(OPENPACK_OPERATIONS),
    exclude_ignore_class=True,
) -&gt; pd.DataFrame:
    &#34;&#34;&#34; Compute evaluation metrics from model outputs (predicted probability).
    Args:
        cfg (DictConfig): config dict.
        outputs (Dict[str, Dict[str, np.ndarray]]): dict object that contains t_idx and y.
            t_idx is a 2d array of target class index with shape=(BATCH_SIZE, WINDOW).
            y is a 3d array of predction probabilities with shape=(BATCH_SIZE, NUM_CLASSES, WINDOW).
        act_set (ActSete, optional): class definition.
        exclude_ignore_class (bool): If true, ignore classes are excluded. (default: True)
    Returns:
        pd.DataFrame
    &#34;&#34;&#34;
    submission = construct_submission_dict(
        outputs, act_set, include_ground_truth=True, cfg=cfg)
    classes = act_set.to_tuple()
    ignore_class_id = act_set.get_ignore_class_id()
    if isinstance(ignore_class_id, tuple):
        raise NotImplementedError()

    # Evaluate
    df_scores = []
    t_id_concat, y_id_concat = [], []
    for key, d in submission.items():
        t_id = d[&#34;ground_truth&#34;]
        y_id = d[&#34;prediction&#34;]

        t_id_concat.append(t_id.copy())
        y_id_concat.append(y_id.copy())

        df_tmp = eval_operation_segmentation(
            t_id,
            y_id,
            classes=classes,
            ignore_class_id=ignore_class_id,
            mode=None)
        df_tmp[&#34;key&#34;] = key
        df_scores.append(df_tmp.reset_index(drop=False))

    # Overall Score
    df_tmp = eval_operation_segmentation(
        np.concatenate(t_id_concat, axis=0),
        np.concatenate(y_id_concat, axis=0),
        classes=classes,
        ignore_class_id=ignore_class_id,
        mode=None,
    )
    df_tmp[&#34;key&#34;] = &#34;all&#34;
    df_scores.append(df_tmp.reset_index(drop=False))

    df_scores = pd.concat(df_scores, axis=0, ignore_index=True)
    return df_scores</code></pre>
</details>
</dd>
<dt id="openpack_toolkit.codalab.operation_segmentation.make_submission_zipfile"><code class="name flex">
<span>def <span class="ident">make_submission_zipfile</span></span>(<span>submission: Dict, logdir: pathlib.Path, metadata: dict = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Check dict contents and generate zip file for codalab submission.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>submission</code></strong> :&ensp;<code>Dict</code></dt>
<dd>submission dict</dd>
<dt><strong><code>logdir</code></strong> :&ensp;<code>Path</code></dt>
<dd>path to the output directory</dd>
<dt><strong><code>metadata</code></strong> :&ensp;<code>dict</code></dt>
<dd>dict of additional information that is included in
<code>submission.json</code>. We recommend to include a data split name.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None (make JSON &amp; zip files)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_submission_zipfile(
        submission: Dict,
        logdir: Path,
        metadata: dict = None) -&gt; None:
    &#34;&#34;&#34;Check dict contents and generate zip file for codalab submission.

    Args:
        submission (Dict): submission dict
        logdir (Path): path to the output directory
        metadata (dict): dict of additional information that is included in
            ``submission.json``. We recommend to include a data split name.
    Returns:
        None (make JSON &amp; zip files)
    &#34;&#34;&#34;
    # Check data format and convert into pure objects
    submission_clean = dict()
    for key, d in submission.items():
        assert isinstance(d, dict)

        record = dict()
        for arr_name, arr in d.items():
            if arr_name not in (&#34;prediction&#34;, &#34;unixtime&#34;):
                logger.warning(
                    f&#34;unexpected entry[{arr_name}] is found in submission dict.&#34;)
            assert isinstance(arr, np.ndarray)
            record[arr_name] = arr.tolist()
        submission_clean[key] = record

    # Add meta data
    if metadata is not None:
        submission_clean[&#34;meta&#34;] = metadata

    # Write JSON file
    path_json = Path(logdir, &#34;submission.json&#34;)
    if path_json.exists():
        os.remove(path_json)
    with open(path_json, &#34;w&#34;) as f:
        json.dump(submission_clean, f)
    logger.info(f&#34;write submission.json to {path_json}&#34;)

    # Make zip file
    path_zip = Path(logdir, &#34;submission.zip&#34;)
    if path_zip.exists():
        os.remove(path_zip)
    with zipfile.ZipFile(path_zip, &#34;w&#34;) as zf:
        zf.write(path_json, arcname=&#34;./submission.json&#34;)
    logger.info(f&#34;write submission.zip to {path_zip}&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="openpack_toolkit.codalab" href="../index.html">openpack_toolkit.codalab</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.eval" href="eval.html">openpack_toolkit.codalab.operation_segmentation.eval</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.utils" href="utils.html">openpack_toolkit.codalab.operation_segmentation.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.construct_submission_dict" href="#openpack_toolkit.codalab.operation_segmentation.construct_submission_dict">construct_submission_dict</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation" href="#openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation">eval_operation_segmentation</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation_wrapper" href="#openpack_toolkit.codalab.operation_segmentation.eval_operation_segmentation_wrapper">eval_operation_segmentation_wrapper</a></code></li>
<li><code><a title="openpack_toolkit.codalab.operation_segmentation.make_submission_zipfile" href="#openpack_toolkit.codalab.operation_segmentation.make_submission_zipfile">make_submission_zipfile</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>